{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasslayy/MNIST-Ensemble-Learning-Project/blob/main/ensemble_learning_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e957e98b",
      "metadata": {
        "id": "e957e98b"
      },
      "source": [
        "# Ensemble Learning on MNIST\n",
        "\n",
        "This notebook implements Questions **8 and 9** from the Ensemble Learning assignment:\n",
        "\n",
        "- Train multiple classifiers on the MNIST dataset (Random Forest, Extra Trees, SVM).\n",
        "- Combine them using **voting** (hard/soft).\n",
        "- Build a **stacking ensemble** (manual blender + `StackingClassifier`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "329eb9f3",
      "metadata": {
        "id": "329eb9f3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4450a870",
      "metadata": {
        "id": "4450a870"
      },
      "source": [
        "## 1. Load and split the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f955df9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f955df9",
        "outputId": "4acd3b45-18a1-4bc0-f8f2-683db522fce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset shape: (70000, 784) Labels shape: (70000,)\n"
          ]
        }
      ],
      "source": [
        "# This may take a moment the first time because it downloads the dataset.\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')  # convert labels to integers\n",
        "\n",
        "print('Full dataset shape:', X.shape, 'Labels shape:', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9233dbe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9233dbe2",
        "outputId": "e3770e47-a3a7-401f-8f12-cc72e1b12828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (50000, 784) Validation set: (10000, 784) Test set: (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "# Use 50,000 for training, 10,000 for validation, 10,000 for testing\n",
        "\n",
        "# First, create a train (60k) / test (10k) split\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=10000, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# Then split the 60k into 50k train / 10k validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=10000, random_state=RANDOM_STATE, stratify=y_train_full\n",
        ")\n",
        "\n",
        "print('Train set:', X_train.shape, 'Validation set:', X_valid.shape, 'Test set:', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "937cf116",
      "metadata": {
        "id": "937cf116"
      },
      "source": [
        "## 2. Define base classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "84a547fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84a547fa",
        "outputId": "78c0e68a-ce5c-498d-dce6-5b9d320ffb24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rf', RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
              " ('et', ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=42)),\n",
              " ('svm',\n",
              "  Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                  ('svc', SVC(probability=True, random_state=42))]))]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Tree-based models (do not require feature scaling)\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "et_clf = ExtraTreesClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# SVM works better with feature scaling. We use a pipeline.\n",
        "svm_clf = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svc', SVC(kernel='rbf', gamma='scale', probability=True, random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "base_estimators = [('rf', rf_clf), ('et', et_clf), ('svm', svm_clf)]\n",
        "base_estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d748d0",
      "metadata": {
        "id": "e7d748d0"
      },
      "source": [
        "## 3. Train and evaluate individual classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3937db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e3937db",
        "outputId": "135b7fb5-be3d-4dea-b5b4-cf834b24ad41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training rf...\n",
            "rf validation accuracy: 0.9717\n",
            "\n",
            "Training et...\n",
            "et validation accuracy: 0.9739\n",
            "\n",
            "Training svm...\n"
          ]
        }
      ],
      "source": [
        "def train_and_eval(clf, X_train, y_train, X_valid, y_valid, name='model'):\n",
        "    print(f'\\nTraining {name}...')\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_valid_pred = clf.predict(X_valid)\n",
        "    valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
        "    print(f'{name} validation accuracy: {valid_acc:.4f}')\n",
        "    return clf, valid_acc\n",
        "\n",
        "trained_clfs = {}\n",
        "valid_scores = {}\n",
        "\n",
        "for name, clf in base_estimators:\n",
        "    model, acc = train_and_eval(clf, X_train, y_train, X_valid, y_valid, name=name)\n",
        "    trained_clfs[name] = model\n",
        "    valid_scores[name] = acc\n",
        "\n",
        "print('\\nValidation accuracies:')\n",
        "for name, acc in valid_scores.items():\n",
        "    print(f'{name}: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a041546c",
      "metadata": {
        "id": "a041546c"
      },
      "source": [
        "## 4. Voting ensemble (hard and soft voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4de236",
      "metadata": {
        "id": "dd4de236"
      },
      "outputs": [],
      "source": [
        "# Hard voting classifier\n",
        "hard_voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', trained_clfs['rf']), ('et', trained_clfs['et']), ('svm', trained_clfs['svm'])],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "print('\\nFitting hard voting classifier (re-uses already fitted estimators)...')\n",
        "hard_voting_clf.fit(X_valid, y_valid)  # this just checks/uses estimators; no refit by default\n",
        "y_valid_pred_hard = hard_voting_clf.predict(X_valid)\n",
        "hard_acc = accuracy_score(y_valid, y_valid_pred_hard)\n",
        "print(f'Hard voting validation accuracy: {hard_acc:.4f}')\n",
        "\n",
        "# Soft voting classifier\n",
        "soft_voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', trained_clfs['rf']), ('et', trained_clfs['et']), ('svm', trained_clfs['svm'])],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "print('\\nFitting soft voting classifier (re-uses already fitted estimators)...')\n",
        "soft_voting_clf.fit(X_valid, y_valid)\n",
        "y_valid_pred_soft = soft_voting_clf.predict(X_valid)\n",
        "soft_acc = accuracy_score(y_valid, y_valid_pred_soft)\n",
        "print(f'Soft voting validation accuracy: {soft_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca7ec44",
      "metadata": {
        "id": "6ca7ec44"
      },
      "source": [
        "## 5. Evaluate best model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b102149",
      "metadata": {
        "id": "8b102149"
      },
      "outputs": [],
      "source": [
        "# Pick the best model on the validation set\n",
        "all_valid_scores = valid_scores.copy()\n",
        "all_valid_scores['hard_voting'] = hard_acc\n",
        "all_valid_scores['soft_voting'] = soft_acc\n",
        "\n",
        "print('\\nAll validation scores:')\n",
        "for name, acc in all_valid_scores.items():\n",
        "    print(f'{name}: {acc:.4f}')\n",
        "\n",
        "best_name = max(all_valid_scores, key=all_valid_scores.get)\n",
        "print(f'\\nBest model on validation set: {best_name}')\n",
        "\n",
        "if best_name == 'hard_voting':\n",
        "    best_model = hard_voting_clf\n",
        "elif best_name == 'soft_voting':\n",
        "    best_model = soft_voting_clf\n",
        "else:\n",
        "    best_model = trained_clfs[best_name]\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nEvaluating {best_name} on the test set...')\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1f38f28",
      "metadata": {
        "id": "c1f38f28"
      },
      "source": [
        "## 6. Manual stacking ensemble (blender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cfe12ed",
      "metadata": {
        "id": "9cfe12ed"
      },
      "outputs": [],
      "source": [
        "# For stacking, we use the trained base models to generate predictions on the validation set.\n",
        "# Each instance in the new training set is a vector of predictions from each classifier.\n",
        "\n",
        "def get_meta_features(models, X):\n",
        "    \"\"\"Return a 2D array where each column is the predictions of one model.\"\"\"\n",
        "    meta_features = []\n",
        "    for name, clf in models.items():\n",
        "        preds = clf.predict(X)\n",
        "        meta_features.append(preds)\n",
        "    return np.vstack(meta_features).T  # shape: [n_samples, n_models]\n",
        "\n",
        "# Create meta-features for validation and test sets\n",
        "meta_X_train = get_meta_features(trained_clfs, X_valid)\n",
        "meta_y_train = y_valid\n",
        "\n",
        "meta_X_test = get_meta_features(trained_clfs, X_test)\n",
        "meta_y_test = y_test\n",
        "\n",
        "print('Meta-feature shape (train):', meta_X_train.shape)\n",
        "\n",
        "# Use a simple logistic regression as the blender\n",
        "blender = LogisticRegression(max_iter=1000, multi_class='auto')\n",
        "blender.fit(meta_X_train, meta_y_train)\n",
        "\n",
        "meta_test_pred = blender.predict(meta_X_test)\n",
        "stacking_acc = accuracy_score(meta_y_test, meta_test_pred)\n",
        "print(f'Stacking ensemble (manual blender) test accuracy: {stacking_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090057ca",
      "metadata": {
        "id": "090057ca"
      },
      "source": [
        "## 7. Using `StackingClassifier`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe17014",
      "metadata": {
        "id": "cfe17014"
      },
      "outputs": [],
      "source": [
        "stack_clf = StackingClassifier(\n",
        "    estimators=[('rf', rf_clf), ('et', et_clf), ('svm', svm_clf)],\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print('\\nTraining StackingClassifier on the training set...')\n",
        "stack_clf.fit(X_train, y_train)\n",
        "\n",
        "y_valid_stack = stack_clf.predict(X_valid)\n",
        "stack_valid_acc = accuracy_score(y_valid, y_valid_stack)\n",
        "print(f'StackingClassifier validation accuracy: {stack_valid_acc:.4f}')\n",
        "\n",
        "y_test_stack = stack_clf.predict(X_test)\n",
        "stack_test_acc = accuracy_score(y_test, y_test_stack)\n",
        "print(f'StackingClassifier test accuracy: {stack_test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53bea29e",
      "metadata": {
        "id": "53bea29e"
      },
      "source": [
        "## 8. Summary of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fab5d8e",
      "metadata": {
        "id": "0fab5d8e"
      },
      "outputs": [],
      "source": [
        "print('\\n=== FINAL COMPARISON (Validation) ===')\n",
        "print('Base models:')\n",
        "for name, acc in valid_scores.items():\n",
        "    print(f'{name}: {acc:.4f}')\n",
        "print(f'Hard voting: {hard_acc:.4f}')\n",
        "print(f'Soft voting: {soft_acc:.4f}')\n",
        "print(f'StackingClassifier (valid): {stack_valid_acc:.4f}')\n",
        "\n",
        "print('\\n=== FINAL COMPARISON (Test) ===')\n",
        "print(f'Best voting/test ({best_name}): {test_acc:.4f}')\n",
        "print(f'Manual stacking (blender) test: {stacking_acc:.4f}')\n",
        "print(f'StackingClassifier test: {stack_test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}